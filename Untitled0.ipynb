{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+Yas+kA7hJO/UNAb7mpUM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayhanbzkrt/Artificial-Intelligence-AI-Tutorial/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5XXpZq9wv2z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web Scraping Nedir?\n",
        "Web scraping, bir web sitesindeki verileri otomatik olarak alma iÅŸlemidir.\n",
        "Yani tarayÄ±cÄ±da bir web sitesine girip kopyalaâ€“yapÄ±ÅŸtÄ±r yaptÄ±ÄŸÄ±n iÅŸlemi Python gibi programlama dilleriyle otomatikleÅŸtiriyoruz.\n",
        "\n",
        "Ã–rnek:\n",
        "\n",
        "Bir haber sitesinden tÃ¼m baÅŸlÄ±klarÄ± Ã§ekmek.\n",
        "\n",
        "Bir e-ticaret sitesindeki Ã¼rÃ¼n fiyatlarÄ±nÄ± toplamak.\n",
        "\n",
        "Hava durumu verilerini her gÃ¼n almak."
      ],
      "metadata": {
        "id": "Z-AeGF_vwzE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ne iÅŸe yarar?\n",
        "Verileri hÄ±zlÄ± ve dÃ¼zenli toplamak\n",
        "\n",
        "GÃ¼ncel iÃ§erikleri analiz etmek\n",
        "\n",
        "Elle yapÄ±lmasÄ± saat sÃ¼recek iÅŸlemleri saniyeler iÃ§inde yapmak\n",
        "\n",
        "Hangi KÃ¼tÃ¼phaneler KullanÄ±lÄ±r?\n",
        "\n",
        "Web scraping iÃ§in en Ã§ok kullanÄ±lan Python kÃ¼tÃ¼phaneleri:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "requests â†’ Web sayfasÄ±na istek gÃ¶nderir, HTML'yi alÄ±r.\n",
        "\n",
        "BeautifulSoup â†’ HTML iÃ§indeki verileri kolayca bulur.\n",
        "\n",
        "pandas â†’ Verileri tabloya Ã§evirir ve iÅŸler.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WNBGBy8Dw5vG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AdÄ±m AdÄ±m Basit Bir Web Scraping Ã–rneÄŸi**\n",
        "1. Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyelim"
      ],
      "metadata": {
        "id": "LxdazelcxQdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW_LtmzUxUI7",
        "outputId": "c58be6cc-2152-48b1-fb30-5a007f1449a3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Sayfa iÃ§eriÄŸini alalÄ±m**"
      ],
      "metadata": {
        "id": "PF1zycCrxXVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://www.bbc.com/news'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n"
      ],
      "metadata": {
        "id": "s15Shg3Bxcxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Haber baÅŸlÄ±klarÄ±nÄ± bulalÄ±m**"
      ],
      "metadata": {
        "id": "uV5br6jmxiO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BBC sitesindeki baÅŸlÄ±klarÄ±n class'Ä± genellikle \"gs-c-promo-heading__title\"\n",
        "headlines = soup.find_all('h3')\n",
        "\n",
        "for i, headline in enumerate(headlines[:10], 1):  # Ä°lk 10 baÅŸlÄ±ÄŸÄ± alalÄ±m\n",
        "    print(f\"{i}. {headline.text.strip()}\")\n"
      ],
      "metadata": {
        "id": "NLuQvzD1xla6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Biraz Daha KullanÄ±ÅŸlÄ± Hale Getirelim (pandas ile tablo)**"
      ],
      "metadata": {
        "id": "WxZD7hrTxpSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "titles = [h.text.strip() for h in headlines[:10]]\n",
        "df = pd.DataFrame({'BBC BaÅŸlÄ±klarÄ±': titles})\n",
        "df\n"
      ],
      "metadata": {
        "id": "gH4llbfExtex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dikkat Edilmesi Gerekenler:**\n",
        "Her siteyi scrape etmek yasal olmayabilir. Robots.txt dosyasÄ±nÄ± kontrol et.\n",
        "\n",
        "AÅŸÄ±rÄ± istek gÃ¶nderme, sunucuyu yorabilir â†’ polite ol!\n",
        "\n",
        "Her sitenin HTML yapÄ±sÄ± farklÄ±dÄ±r â†’ class/id deÄŸiÅŸebilir."
      ],
      "metadata": {
        "id": "QpadVxBExzCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mini GÃ¶rev:\n",
        "AÅŸaÄŸÄ±daki sitelerden birini seÃ§:\n",
        "\n",
        "https://quotes.toscrape.com\n",
        "\n",
        "https://books.toscrape.com\n",
        "\n",
        "Ve oradaki baÅŸlÄ±klarÄ±, kitap isimlerini ya da yazarlarÄ± Ã§ekmeye Ã§alÄ±ÅŸ"
      ],
      "metadata": {
        "id": "i4pSgvBcx6Y0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ›’ GÃ¶rev:\n",
        "â€œhttps://books.toscrape.comâ€ sitesine gidelim,\n",
        "\n",
        "Her sayfadaki kitaplarÄ±n isimlerini ve fiyatlarÄ±nÄ± Ã§ekip tabloya dÃ¶kelim."
      ],
      "metadata": {
        "id": "O3e50bZRyGD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… 1. Gerekli KurulumlarÄ± YapalÄ±m (Google Colab iÃ§in)"
      ],
      "metadata": {
        "id": "BKh4onPlyMT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4\n"
      ],
      "metadata": {
        "id": "FvRAfvHByZ-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… 2. Web SayfasÄ±nÄ± Ã‡ek & Ä°ncele"
      ],
      "metadata": {
        "id": "zcTY0oYHyWQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://books.toscrape.com/catalogue/page-1.html'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n"
      ],
      "metadata": {
        "id": "RdWMZODXyY0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… 3. KitaplarÄ±n AdÄ±nÄ± ve FiyatÄ±nÄ± Bul"
      ],
      "metadata": {
        "id": "F7jBnjTtyeYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books = soup.find_all('article', class_='product_pod')\n",
        "\n",
        "for book in books:\n",
        "    title = book.h3.a['title']\n",
        "    price = book.find('p', class_='price_color').text\n",
        "    print(f\"ğŸ“˜ {title} â€” ğŸ’° {price}\")\n"
      ],
      "metadata": {
        "id": "J2Fbr85Fyi9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… 4. Verileri Tabloya DÃ¶kelim (pandas ile)"
      ],
      "metadata": {
        "id": "H0Ho30ltymR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "titles = []\n",
        "prices = []\n",
        "\n",
        "for book in books:\n",
        "    titles.append(book.h3.a['title'])\n",
        "    prices.append(book.find('p', class_='price_color').text)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'Kitap AdÄ±': titles,\n",
        "    'Fiyat': prices\n",
        "})\n",
        "\n",
        "df\n"
      ],
      "metadata": {
        "id": "cUVpiYi1ynav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ğŸŒ€ BONUS: Birden Fazla SayfayÄ± DolaÅŸ (Level 2)**"
      ],
      "metadata": {
        "id": "1QlPVG8Kysur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_titles = []\n",
        "all_prices = []\n",
        "\n",
        "for page in range(1, 6):  # Åimdilik ilk 5 sayfa (50 sayfa yapmak kolay)\n",
        "    url = f'https://books.toscrape.com/catalogue/page-{page}.html'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    books = soup.find_all('article', class_='product_pod')\n",
        "\n",
        "    for book in books:\n",
        "        all_titles.append(book.h3.a['title'])\n",
        "        all_prices.append(book.find('p', class_='price_color').text)\n",
        "\n",
        "df_all = pd.DataFrame({\n",
        "    'Kitap AdÄ±': all_titles,\n",
        "    'Fiyat': all_prices\n",
        "})\n",
        "\n",
        "df_all\n"
      ],
      "metadata": {
        "id": "qNK39uX2yv0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ® Ekstra GÃ¶revler (Gamified):\n",
        "\n",
        "**Seviye\tGÃ¶rev\tAÃ§Ä±klama**\n",
        "\n",
        "ğŸŸ¢ BaÅŸlangÄ±Ã§\tBaÅŸlÄ±klarÄ± Ã§ek\tKitap baÅŸlÄ±klarÄ±nÄ± doÄŸru al\n",
        "\n",
        "ğŸŸ¡ Orta\tFiyatlarÄ± tabloya dÃ¶k\tHer kitap iÃ§in fiyatÄ± gÃ¶ster\n",
        "\n",
        "ğŸ”µ Zor\tTÃ¼m sayfalarÄ± gez\tDÃ¶ngÃ¼ kur, 50 sayfa gez\n",
        "\n",
        "ğŸŸ£ Usta\tStok durumu + puanlarÄ± Ã§ek\tSayfada varsa In stock, Rating gibi ekstralarÄ± al"
      ],
      "metadata": {
        "id": "oqK59__ky0we"
      }
    }
  ]
}