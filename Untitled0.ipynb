{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+Yas+kA7hJO/UNAb7mpUM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayhanbzkrt/Artificial-Intelligence-AI-Tutorial/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5XXpZq9wv2z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web Scraping Nedir?\n",
        "Web scraping, bir web sitesindeki verileri otomatik olarak alma işlemidir.\n",
        "Yani tarayıcıda bir web sitesine girip kopyala–yapıştır yaptığın işlemi Python gibi programlama dilleriyle otomatikleştiriyoruz.\n",
        "\n",
        "Örnek:\n",
        "\n",
        "Bir haber sitesinden tüm başlıkları çekmek.\n",
        "\n",
        "Bir e-ticaret sitesindeki ürün fiyatlarını toplamak.\n",
        "\n",
        "Hava durumu verilerini her gün almak."
      ],
      "metadata": {
        "id": "Z-AeGF_vwzE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ne işe yarar?\n",
        "Verileri hızlı ve düzenli toplamak\n",
        "\n",
        "Güncel içerikleri analiz etmek\n",
        "\n",
        "Elle yapılması saat sürecek işlemleri saniyeler içinde yapmak\n",
        "\n",
        "Hangi Kütüphaneler Kullanılır?\n",
        "\n",
        "Web scraping için en çok kullanılan Python kütüphaneleri:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "requests → Web sayfasına istek gönderir, HTML'yi alır.\n",
        "\n",
        "BeautifulSoup → HTML içindeki verileri kolayca bulur.\n",
        "\n",
        "pandas → Verileri tabloya çevirir ve işler.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WNBGBy8Dw5vG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adım Adım Basit Bir Web Scraping Örneği**\n",
        "1. Gerekli kütüphaneleri yükleyelim"
      ],
      "metadata": {
        "id": "LxdazelcxQdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW_LtmzUxUI7",
        "outputId": "c58be6cc-2152-48b1-fb30-5a007f1449a3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Sayfa içeriğini alalım**"
      ],
      "metadata": {
        "id": "PF1zycCrxXVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://www.bbc.com/news'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n"
      ],
      "metadata": {
        "id": "s15Shg3Bxcxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Haber başlıklarını bulalım**"
      ],
      "metadata": {
        "id": "uV5br6jmxiO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BBC sitesindeki başlıkların class'ı genellikle \"gs-c-promo-heading__title\"\n",
        "headlines = soup.find_all('h3')\n",
        "\n",
        "for i, headline in enumerate(headlines[:10], 1):  # İlk 10 başlığı alalım\n",
        "    print(f\"{i}. {headline.text.strip()}\")\n"
      ],
      "metadata": {
        "id": "NLuQvzD1xla6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Biraz Daha Kullanışlı Hale Getirelim (pandas ile tablo)**"
      ],
      "metadata": {
        "id": "WxZD7hrTxpSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "titles = [h.text.strip() for h in headlines[:10]]\n",
        "df = pd.DataFrame({'BBC Başlıkları': titles})\n",
        "df\n"
      ],
      "metadata": {
        "id": "gH4llbfExtex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dikkat Edilmesi Gerekenler:**\n",
        "Her siteyi scrape etmek yasal olmayabilir. Robots.txt dosyasını kontrol et.\n",
        "\n",
        "Aşırı istek gönderme, sunucuyu yorabilir → polite ol!\n",
        "\n",
        "Her sitenin HTML yapısı farklıdır → class/id değişebilir."
      ],
      "metadata": {
        "id": "QpadVxBExzCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mini Görev:\n",
        "Aşağıdaki sitelerden birini seç:\n",
        "\n",
        "https://quotes.toscrape.com\n",
        "\n",
        "https://books.toscrape.com\n",
        "\n",
        "Ve oradaki başlıkları, kitap isimlerini ya da yazarları çekmeye çalış"
      ],
      "metadata": {
        "id": "i4pSgvBcx6Y0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛒 Görev:\n",
        "“https://books.toscrape.com” sitesine gidelim,\n",
        "\n",
        "Her sayfadaki kitapların isimlerini ve fiyatlarını çekip tabloya dökelim."
      ],
      "metadata": {
        "id": "O3e50bZRyGD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ 1. Gerekli Kurulumları Yapalım (Google Colab için)"
      ],
      "metadata": {
        "id": "BKh4onPlyMT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4\n"
      ],
      "metadata": {
        "id": "FvRAfvHByZ-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ 2. Web Sayfasını Çek & İncele"
      ],
      "metadata": {
        "id": "zcTY0oYHyWQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://books.toscrape.com/catalogue/page-1.html'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n"
      ],
      "metadata": {
        "id": "RdWMZODXyY0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ 3. Kitapların Adını ve Fiyatını Bul"
      ],
      "metadata": {
        "id": "F7jBnjTtyeYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books = soup.find_all('article', class_='product_pod')\n",
        "\n",
        "for book in books:\n",
        "    title = book.h3.a['title']\n",
        "    price = book.find('p', class_='price_color').text\n",
        "    print(f\"📘 {title} — 💰 {price}\")\n"
      ],
      "metadata": {
        "id": "J2Fbr85Fyi9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ 4. Verileri Tabloya Dökelim (pandas ile)"
      ],
      "metadata": {
        "id": "H0Ho30ltymR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "titles = []\n",
        "prices = []\n",
        "\n",
        "for book in books:\n",
        "    titles.append(book.h3.a['title'])\n",
        "    prices.append(book.find('p', class_='price_color').text)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'Kitap Adı': titles,\n",
        "    'Fiyat': prices\n",
        "})\n",
        "\n",
        "df\n"
      ],
      "metadata": {
        "id": "cUVpiYi1ynav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**🌀 BONUS: Birden Fazla Sayfayı Dolaş (Level 2)**"
      ],
      "metadata": {
        "id": "1QlPVG8Kysur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_titles = []\n",
        "all_prices = []\n",
        "\n",
        "for page in range(1, 6):  # Şimdilik ilk 5 sayfa (50 sayfa yapmak kolay)\n",
        "    url = f'https://books.toscrape.com/catalogue/page-{page}.html'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    books = soup.find_all('article', class_='product_pod')\n",
        "\n",
        "    for book in books:\n",
        "        all_titles.append(book.h3.a['title'])\n",
        "        all_prices.append(book.find('p', class_='price_color').text)\n",
        "\n",
        "df_all = pd.DataFrame({\n",
        "    'Kitap Adı': all_titles,\n",
        "    'Fiyat': all_prices\n",
        "})\n",
        "\n",
        "df_all\n"
      ],
      "metadata": {
        "id": "qNK39uX2yv0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🎮 Ekstra Görevler (Gamified):\n",
        "\n",
        "**Seviye\tGörev\tAçıklama**\n",
        "\n",
        "🟢 Başlangıç\tBaşlıkları çek\tKitap başlıklarını doğru al\n",
        "\n",
        "🟡 Orta\tFiyatları tabloya dök\tHer kitap için fiyatı göster\n",
        "\n",
        "🔵 Zor\tTüm sayfaları gez\tDöngü kur, 50 sayfa gez\n",
        "\n",
        "🟣 Usta\tStok durumu + puanları çek\tSayfada varsa In stock, Rating gibi ekstraları al"
      ],
      "metadata": {
        "id": "oqK59__ky0we"
      }
    }
  ]
}